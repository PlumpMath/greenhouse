
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Tutorial &mdash; greenhouse 2.0.0 documentation</title>
    
    <link rel="stylesheet" href="../static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '2.0.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../static/jquery.js"></script>
    <script type="text/javascript" src="../static/underscore.js"></script>
    <script type="text/javascript" src="../static/doctools.js"></script>
    <link rel="top" title="greenhouse 2.0.0 documentation" href="../index.html" />
    <link rel="next" title="greenhouse.scheduler – Interacting With The Greenhouse Scheduler" href="../greenhouse/scheduler.html" />
    <link rel="prev" title="Welcome to the Greenhouse Documentation!" href="../index.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../greenhouse/scheduler.html" title="greenhouse.scheduler – Interacting With The Greenhouse Scheduler"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="../index.html" title="Welcome to the Greenhouse Documentation!"
             accesskey="P">previous</a> |</li>
        <li><a href="../index.html">greenhouse 2.0.0 documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="tutorial">
<h1>Tutorial<a class="headerlink" href="#tutorial" title="Permalink to this headline">¶</a></h1>
<div class="section" id="grabbing-urls-in-parallel">
<h2>Grabbing URLs in Parallel<a class="headerlink" href="#grabbing-urls-in-parallel" title="Permalink to this headline">¶</a></h2>
<p>Since the strength of greenhouse is the ability to do I/O operations in
parallel, lets take the simple example of fetching a list of URLs with HTTP
and explore the APIs that greenhouse makes available.</p>
<div class="section" id="just-schedule-the-coroutines">
<h3>Just Schedule the Coroutines<a class="headerlink" href="#just-schedule-the-coroutines" title="Permalink to this headline">¶</a></h3>
<p>A greenhouse coroutine wraps a function, so since our coroutines will be
fetching urls, let&#8217;s write a function that fetches a URL and places it in a
results collector.</p>
<p>To get the urls we can just use the simple standard library module urllib2, but
in order to make sure that it only blocks a coroutine we need to use greenhouse
to import it.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">greenhouse</span>
<span class="n">urllib2</span> <span class="o">=</span> <span class="n">greenhouse</span><span class="o">.</span><span class="n">patched</span><span class="p">(</span><span class="s">&quot;urllib2&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_get_one_url</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">results</span><span class="p">):</span>
    <span class="n">page</span> <span class="o">=</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">url</span><span class="p">,</span> <span class="n">page</span><span class="p">))</span>
</pre></div>
</div>
<p>For the full implementation we just need to schedule a coroutine for each url
we need to grab.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">get_urls</span><span class="p">(</span><span class="n">urls</span><span class="p">):</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
        <span class="n">greenhouse</span><span class="o">.</span><span class="n">schedule</span><span class="p">(</span><span class="n">_get_one_url</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">results</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">results</span>
</pre></div>
</div>
<p>So this starts <em>all</em> the I/O in parallel and returns a list into which the
results will appear as they come in.</p>
<p>That&#8217;s nice, but we&#8217;d really like some better notification when everything is
finished. We can probably live with blocking until all the results come back as
long as we know that they are being fetched in parallel. So let&#8217;s use one of
the simplest synchronization utilities available,
<tt class="xref py py-class docutils literal"><span class="pre">Event</span></tt>, and have it trigger when all the
results are in.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">greenhouse</span>
<span class="n">urllib2</span> <span class="o">=</span> <span class="n">greenhouse</span><span class="o">.</span><span class="n">patched</span><span class="p">(</span><span class="s">&quot;urllib2&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_get_one_url</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">done_event</span><span class="p">):</span>
    <span class="n">page</span> <span class="o">=</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">url</span><span class="p">,</span> <span class="n">page</span><span class="p">))</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="n">count</span><span class="p">:</span>
        <span class="n">done_event</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">get_urls</span><span class="p">(</span><span class="n">urls</span><span class="p">):</span>
    <span class="n">count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">urls</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">done</span> <span class="o">=</span> <span class="n">greenhouse</span><span class="o">.</span><span class="n">Event</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
        <span class="n">greenhouse</span><span class="o">.</span><span class="n">schedule</span><span class="p">(</span><span class="n">_get_one_url</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">done</span><span class="p">))</span>

    <span class="n">done</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">results</span>
</pre></div>
</div>
<p>That&#8217;ll about do it! We schedule one coroutine for each url we need fetched and
have that coroutine get it, then block on the
<tt class="xref py py-class docutils literal"><span class="pre">event</span></tt> until the last one has come back.</p>
</div>
<div class="section" id="drive-it-off-a-queue">
<h3>Drive It Off a Queue<a class="headerlink" href="#drive-it-off-a-queue" title="Permalink to this headline">¶</a></h3>
<p>The above implementation still has at least one deficiency though &#8211; we may
want to cap the amount of parallelism in case we wind up with an especially
long list of urls, in which case each coroutine would need to fetch multiple
urls in serial. But they should all be pulling from a single list so that it is
the coroutine that comes back with its first result the fastest that fetches a
second one.</p>
<p>Sounds like a job for a queue. We&#8217;ll use a
<tt class="xref py py-class docutils literal"><span class="pre">Queue</span></tt> and follow the urls with a sentinel
stopper for each coro we have running.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">greenhouse</span>
<span class="n">urllib2</span> <span class="o">=</span> <span class="n">greenhouse</span><span class="o">.</span><span class="n">patched</span><span class="p">(</span><span class="s">&quot;urllib2&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_get_multiple_urls</span><span class="p">(</span><span class="n">input_queue</span><span class="p">,</span> <span class="n">output_queue</span><span class="p">,</span> <span class="n">stop</span><span class="p">):</span>
    <span class="k">while</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">url</span> <span class="o">=</span> <span class="n">input_queue</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">url</span> <span class="ow">is</span> <span class="n">stop</span><span class="p">:</span>
            <span class="k">break</span>

        <span class="n">page</span> <span class="o">=</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">output_queue</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="n">url</span><span class="p">,</span> <span class="n">page</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">get_urls_queue</span><span class="p">(</span><span class="n">urls</span><span class="p">,</span> <span class="n">parallel_cap</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">in_q</span> <span class="o">=</span> <span class="n">greenhouse</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
    <span class="n">out_q</span> <span class="o">=</span> <span class="n">greenhouse</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
    <span class="n">stop</span> <span class="o">=</span> <span class="nb">object</span><span class="p">()</span>
    <span class="n">parallel_cap</span> <span class="o">=</span> <span class="n">parallel_cap</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">urls</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">parallel_cap</span><span class="p">):</span>
        <span class="n">greenhouse</span><span class="o">.</span><span class="n">schedule</span><span class="p">(</span><span class="n">_get_multiple_urls</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">in_q</span><span class="p">,</span> <span class="n">out_q</span><span class="p">,</span> <span class="n">stop</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
        <span class="n">in_q</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">parallel_cap</span><span class="p">):</span>
        <span class="n">in_q</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">stop</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">out_q</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
</pre></div>
</div>
<p>By also driving the output off of a <tt class="xref py py-class docutils literal"><span class="pre">Queue</span></tt>, we
are able to yield the results one at a time which is another nice win.</p>
</div>
<div class="section" id="pool-your-coroutines">
<h3>Pool Your Coroutines<a class="headerlink" href="#pool-your-coroutines" title="Permalink to this headline">¶</a></h3>
<p>The pattern above using an input and output queue is a fairly common one and
easy abstract away, so that&#8217;s why we have <a class="reference internal" href="../greenhouse/pool.html#greenhouse.pool.Pool" title="greenhouse.pool.Pool"><tt class="xref py py-class docutils literal"><span class="pre">Pools</span></tt></a>.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">greenhouse</span>
<span class="n">urllib2</span> <span class="o">=</span> <span class="n">greenhouse</span><span class="o">.</span><span class="n">patched</span><span class="p">(</span><span class="s">&quot;urllib2&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_pool_job</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>

<span class="k">def</span> <span class="nf">get_urls_pool</span><span class="p">(</span><span class="n">urls</span><span class="p">,</span> <span class="n">parallel_cap</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">parallel_cap</span> <span class="o">=</span> <span class="n">parallel_cap</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">urls</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">greenhouse</span><span class="o">.</span><span class="n">Pool</span><span class="p">(</span><span class="n">_pool_job</span><span class="p">,</span> <span class="n">parallel_cap</span><span class="p">)</span> <span class="k">as</span> <span class="n">pool</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
            <span class="n">pool</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">pool</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
</pre></div>
</div>
<p>The <a class="reference internal" href="../greenhouse/pool.html#greenhouse.pool.Pool" title="greenhouse.pool.Pool"><tt class="xref py py-class docutils literal"><span class="pre">Pool</span></tt></a> class handles some of the mundane
things in our queue example above: having the coros loop until they get the
stopper, scheduling them, sending the stopper through. The context manager
use in this example simply calls <a class="reference internal" href="../greenhouse/pool.html#greenhouse.pool.Pool.start" title="greenhouse.pool.Pool.start"><tt class="xref py py-meth docutils literal"><span class="pre">start()</span></tt></a> in
the entry, and <a class="reference internal" href="../greenhouse/pool.html#greenhouse.pool.Pool.close" title="greenhouse.pool.Pool.close"><tt class="xref py py-meth docutils literal"><span class="pre">close()</span></tt></a> in the exit.</p>
</div>
<div class="section" id="order-matters">
<h3>Order Matters<a class="headerlink" href="#order-matters" title="Permalink to this headline">¶</a></h3>
<p>One other deficiency of every implementation so far has been that they don&#8217;t
necessarily produce the results in order, which is why we have had to include
the url with its result all along. To order them we&#8217;d have to either wait until
they were all finished and then sort them, or we could keep a cache of those
results that came in out of order and re-order on the fly. Luckily there is
<a class="reference internal" href="../greenhouse/pool.html#greenhouse.pool.OrderedPool" title="greenhouse.pool.OrderedPool"><tt class="xref py py-class docutils literal"><span class="pre">OrderedPool</span></tt></a>, which does the second
approach for us.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">greenhouse</span>
<span class="n">urllib2</span> <span class="o">=</span> <span class="n">greenhouse</span><span class="o">.</span><span class="n">patched</span><span class="p">(</span><span class="s">&quot;urllib2&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_pool_job</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">get_urls_ordered_pool</span><span class="p">(</span><span class="n">urls</span><span class="p">,</span> <span class="n">parallel_cap</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">parallel_cap</span> <span class="o">=</span> <span class="n">parallel_cap</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">urls</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">greenhouse</span><span class="o">.</span><span class="n">OrderedPool</span><span class="p">(</span><span class="n">_pool_job</span><span class="p">,</span> <span class="n">parallel_cap</span><span class="p">)</span> <span class="k">as</span> <span class="n">pool</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
            <span class="n">pool</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">pool</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="a-further-abstraction">
<h3>A Further Abstraction<a class="headerlink" href="#a-further-abstraction" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../greenhouse/pool.html#greenhouse.pool.OrderedPool" title="greenhouse.pool.OrderedPool"><tt class="xref py py-class docutils literal"><span class="pre">OrderedPool</span></tt></a> is great in that it can be a
persistent object and accept jobs and return results over a long period of
time, but for our usage here we just need to crank through a list and be done
with it. <a class="reference internal" href="../greenhouse/pool.html#greenhouse.pool.map" title="greenhouse.pool.map"><tt class="xref py py-func docutils literal"><span class="pre">greenhouse.map</span></tt></a> is a nice abstraction of
<a class="reference internal" href="../greenhouse/pool.html#greenhouse.pool.OrderedPool" title="greenhouse.pool.OrderedPool"><tt class="xref py py-class docutils literal"><span class="pre">OrderedPool</span></tt></a> for that purpose. It works
just like the standard python <tt class="docutils literal"><span class="pre">map</span></tt> function, except that it spreads the jobs
across an <a class="reference internal" href="../greenhouse/pool.html#greenhouse.pool.OrderedPool" title="greenhouse.pool.OrderedPool"><tt class="xref py py-class docutils literal"><span class="pre">OrderedPool</span></tt></a> (and takes an
optional argument for the number of workers it should have)</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">greenhouse</span>
<span class="n">urllib2</span> <span class="o">=</span> <span class="n">greenhouse</span><span class="o">.</span><span class="n">patched</span><span class="p">(</span><span class="s">&quot;urllib2&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_urls_map</span><span class="p">(</span><span class="n">urls</span><span class="p">,</span> <span class="n">parallel_cap</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">parallel_cap</span> <span class="o">=</span> <span class="n">parallel_cap</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">urls</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">greenhouse</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">url</span><span class="p">:</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">(),</span>
        <span class="n">urls</span><span class="p">,</span>
        <span class="n">pool_size</span><span class="o">=</span><span class="n">parallel_cap</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Tutorial</a><ul>
<li><a class="reference internal" href="#grabbing-urls-in-parallel">Grabbing URLs in Parallel</a><ul>
<li><a class="reference internal" href="#just-schedule-the-coroutines">Just Schedule the Coroutines</a></li>
<li><a class="reference internal" href="#drive-it-off-a-queue">Drive It Off a Queue</a></li>
<li><a class="reference internal" href="#pool-your-coroutines">Pool Your Coroutines</a></li>
<li><a class="reference internal" href="#order-matters">Order Matters</a></li>
<li><a class="reference internal" href="#a-further-abstraction">A Further Abstraction</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="../index.html"
                        title="previous chapter">Welcome to the Greenhouse Documentation!</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../greenhouse/scheduler.html"
                        title="next chapter"><tt class="docutils literal docutils literal docutils literal"><span class="pre">greenhouse.scheduler</span></tt> &#8211; Interacting With The Greenhouse Scheduler</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="../sources/tutorial/parallel-urls.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../greenhouse/scheduler.html" title="greenhouse.scheduler – Interacting With The Greenhouse Scheduler"
             >next</a> |</li>
        <li class="right" >
          <a href="../index.html" title="Welcome to the Greenhouse Documentation!"
             >previous</a> |</li>
        <li><a href="../index.html">greenhouse 2.0.0 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2010, Travis J Parker.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3.
    </div>
  </body>
</html>